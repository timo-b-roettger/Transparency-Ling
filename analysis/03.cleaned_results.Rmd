---
title: "Cleaned Results"
author: "Erin M. Buchanan"
date: "Last Knitted: `r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
# knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = FALSE, include = FALSE)
```

```{r libraries}
library(rio)
library(dplyr)
library(stringi)
library(tidyr)
library(psych)
library(ggplot2)
library(maps)
library(countrycode)
library(webr)
library(patchwork)
library(papaja)
library(RColorBrewer)
library(ggdist)
library(forcats)



# define handy function 
'%!in%' <- function(x,y)!('%in%'(x,y))
```

```{r data_imports}
DF <- import("02.data_typofixes.csv")
openaccessDF <- import("../analysis/OA_Coding_10_2021.xlsx") %>% select(-`...9`) %>% filter(!is.na(row_num))
```

## 3.1 Sample characteristics

```{r sample-size}
sample_size <- length(table(DF$ArticleID))

# fix up ones to be included 
DF$ArticleIssues <- gsub("Article published in 2011|Article published in 2014|Article published in 2017\\?|This article seems to be more about education \\(in bilingual contexts\\) than about language. But it has been pre-screened, so not sure about that.", "There are no issues", DF$ArticleIssues)

# figure out how excluded
reasons_excluded <- table(DF$ArticleIssues, DF$Agree)

# total exclude 
total_excluded <- sum(reasons_excluded[ , 1]) + sum(reasons_excluded[1:3, 2])
```

Sample characteristics for all `r sample_size` articles are displayed in Table 2 and Figure 1. `r total_excluded` (`r round(total_excluded/sample_size*100, 1)`%) Articles were excluded due to not being in English (`r round(sum(reasons_excluded[2, ])/sample_size*100, 1)`%), not being about language according to our definition above (`r round(sum(reasons_excluded[1, ])/sample_size*100, 1)`%), not being accessible (`r round(sum(reasons_excluded[3, ])/sample_size*100, 1)`%) or other reasons (`r round(reasons_excluded[4, 1]/sample_size*100, 1)`%).

```{r code-language}
# lower case to normalize
DF$ArticleLanguage <- tolower(DF$ArticleLanguage)

# normalizing languages 
DF$ArticleLanguage <- gsub("$mandarin^", "chinese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("bilingual english-mandarin", "english, chinese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('asl', 'american sign language', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('\\/', ',', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub(' and ', ',', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('cross linguistic', 'cross-linguistic', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("english as a second language", "english", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("esl", "english", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("l2 ", "", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("irish english|tyneside english", "english", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("standard greek", "greek", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("portugese", "portuguese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("chinese-cantonese", "chinese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("nederlandse gebarentaal", "dutch sign language", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("shetland, scottish", "", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('"|old|\\(|\\)|subjects:|stimuli:|\\?|as a second language|shetland|middle|mandarin|european|cameroon|british|-putonghua|cypriot|fiji|australian', '', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("multilingual context 10\\+ languages|multilingualism", "cross-linguistic", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("quecha", "quechua", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("^, ", "", DF$ArticleLanguage)
DF$ArticleLanguage <- trimws(DF$ArticleLanguage)
DF$ArticleLanguage[DF$ArticleLanguage == ""] <- NA
DF$ArticleLanguage[DF$ArticleLanguage == "na"] <- NA

# wide to long format 
langDF <- DF %>% 
  select(ArticleLanguage, year_split, ArticleID) %>% 
  separate(ArticleLanguage, sep = ",", into = c("A", "B", "C", "D"), 
           extra = "warn") %>% 
  pivot_longer(cols = c(A,B,C,D)) %>% 
  filter(!is.na(value)) %>% 
  select(year_split, value, ArticleID) %>% 
  rename(language = value) %>% 
  filter(language != "")

# these damned "spaces" what a dumb hack
langDF$language <- gsub("[^[:alnum:]]", "9", langDF$language)
langDF$language <- gsub("^9+(.+)", "\\1", langDF$language)
langDF$language <- gsub("(.+)9+$", "\\1", langDF$language)
langDF$language <- gsub("9", " ", langDF$language)

# average number of languages
count_lang <- langDF %>% 
  group_by(ArticleID, year_split) %>% 
  summarize(sample_size = n(), .groups = "keep") 

# create data for graph 
lang_summary_all <- langDF %>% 
  mutate(language_new = ifelse(language %!in% c("english", "universal", "spanish", "chinese", "cross linguistic", "german"),
                           "other", language)) %>% 
  group_by(language_new, year_split) %>% 
  summarise(frequency = n(), .groups = "keep") %>% 
  ungroup() %>% 
  mutate(language_new = factor(tools::toTitleCase(language_new), 
                               levels = unique(tools::toTitleCase(language_new)), ordered = T)) %>% 
  mutate(year_split = factor(year_split, levels = c("Pre-OS", "After-OS")))

# please someone make this in one pipeline
freq_split <- lang_summary_all %>% 
  group_by(year_split) %>% 
  summarise(frequency_split = sum(frequency), .groups = "keep") %>% 
  ungroup() %>% 
  full_join(lang_summary_all) %>% 
  mutate(prop = round(frequency / frequency_split, 3) * 100) %>% 
  group_by(year_split) %>% 
  arrange(desc(prop)) %>%
  ungroup()

# make pretty for graph
freq_split$language_new <- factor(freq_split$language_new,
                levels = c("Other", "Chinese", "German", 
                           "Spanish", "Cross Linguistic", 
                           "Universal", "English"))

# rearrange pos
freq_split <- freq_split %>% 
  arrange(desc(language_new)) %>% 
  group_by(year_split) %>% 
  mutate(pos = cumsum(prop)-.5*(prop))

# change for labels for manuscript
freq_split$year_split2 <- factor(freq_split$year_split, 
                                 levels = c("Pre-OS", "After-OS"),
                                 labels = c("Pre-RC", "Post-RC"))

# make the graph 
bar_languages <- 
  ggplot(freq_split, aes(x = year_split2, 
                         y =  prop, 
                         fill = language_new)) +
  geom_bar(stat = "identity",
           #col = "black",
           position = position_stack(),
           color = "black", 
           size = 0.1) +
  geom_text(data = freq_split[freq_split$language_new %in% c("English", "Other", "Universal"),],
            aes(x = year_split2,
                y = pos,
                label = paste0(prop, "%")),
            color = c("white", "white", "black", "black", "white", "white")) + 
  labs(title = "B: Languages Sampled",
       x = "",
       y = "") + 
  scale_x_discrete(limits = c("Pre-RC", "Post-RC")) +
  scale_y_continuous(breaks = c(0, 25, 50, 75, 100), 
                     labels = c("0%", "25%", "50%", "75%", "100%")) + 
  guides(fill = guide_legend(title="Target Language(s)")) +
  scale_fill_brewer(palette="PRGn") + 
  theme_minimal() +
  theme(
    legend.position = "right",
    plot.title = element_text(face = "bold",
                                       size = 14),
    plot.subtitle = element_text(size = 12)
  )

```

```{r code-country}
# fix up typos
DF$CountryAuthor[DF$CountryAuthor == ""] <- NA

# do country regions
DF$CountryCode <- countrycode(sourcevar = DF$CountryAuthor,
                              origin = 'country.name', 
                              destination = 'un.regionsub.name')
DF$CountryCode[is.na(DF$CountryCode)] <- "Unknown"

DF$CountryCode[DF$CountryAuthor == "Taiwan"] <- "Eastern Asia"

DF$CountryCode2 <- DF$CountryCode
DF$CountryCode2 <- gsub(".* Asia.*", "Asia", DF$CountryCode2)
DF$CountryCode2 <- gsub("Melanesia|.*Africa.*|.*Latin America.*", "Other", DF$CountryCode2)

DF$CountryCode2 <- 
  factor(DF$CountryCode2, 
         levels = c("Unknown", "Other", "Eastern Europe", 
                    "Australia and New Zealand", "Southern Europe",  
                     "Western Europe", "Northern Europe", "Asia", 
                    "Northern America"))

country_summary <- DF %>% 
      group_by(year_split, CountryCode2) %>% 
      summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split) %>% 
  mutate(prop = round(n / sum(n)*100, 1)) %>% 
  arrange(desc(CountryCode2)) %>% 
  mutate(pos = cumsum(prop)-.5*(prop))

# change labels for publication
country_summary$year_split2 <- factor(country_summary$year_split,
                                      levels = c("Pre-OS", "After-OS"),
                                      labels = c("Pre-RC", "Post-RC"))
  
# create bar plot of countries 
bar_countries <- 
  ggplot(country_summary, aes(x = year_split2, 
                         y =  prop, 
                         fill = CountryCode2)) +
  geom_bar(stat = "identity",
           #col = "black",
           position = position_stack(),
           color = "black", 
           size = 0.1) +
  geom_text(data = country_summary[country_summary$CountryCode2 %in% c("Northern America", "Northern Europe", "Asia", "Western Europe"),],
            aes(x = year_split2,
                y = pos,
                label = paste0(prop, "%")),
            color = c("white", "white", "white", "white",
                      "black", "black", "black", "black")) + 
  labs(title = "A: Author Affiliation",
       x = "",
       y = "") + 
  scale_x_discrete(limits = c("Pre-RC","Post-RC")) +
  scale_y_continuous(breaks = c(0, 25, 50, 75, 100), 
                     labels = c("0%", "25%", "50%", "75%", "100%"),
                     position = "right") + 
  guides(fill = guide_legend(title = "Country", 
                             title.hjust = 1, 
                             label.position = "left", 
                             label.hjust = 1, 
                             label.vjust = 0.5)) + 
  scale_fill_brewer(palette="BrBG") + 
  theme_minimal() +
  theme(
    legend.position = "left",
    plot.title = element_text(face = "bold",
                              size = 14,
                              hjust = 1),
    plot.subtitle = element_text(size = 12)
  ) 
```

```{r code-JIF}
# import JIF
JIF <- import("../analysis/JIF_update.xlsx")

# create cleaned up DF
JIF_new <- JIF %>%  
  filter(JIFYear != "NA") %>% 
  mutate(JIF = as.numeric(JIF),
         JIFYear = as.numeric(JIFYear),
    year_split = ifelse(JIFYear > 2016, "After-OS", "Pre-OS"))

# aggregate data frame 
JIF_new_agg <- JIF_new %>% 
  group_by(year_split) %>% 
  summarize(sum = n(),
            se = sd(JIF, na.rm = TRUE) / sqrt(sum),
            JIF = median(JIF, na.rm = TRUE))

JIF_new$year_split <- factor(JIF_new$year_split, 
                      levels = c("Pre-OS", "After-OS"))

# make plot picture 
JIF_plot <- 
ggplot(JIF_new,
       aes(x = year_split,
           #y = JIF 
           y = JIF
           #colour = year_split
           )) +
    stat_slab(data = JIF_new,
            aes(y = JIF,
                fill_ramp = stat(cut_cdf_qi(cdf, 
                                            .width = c(.5, .8, .95),
                                            labels = scales::percent_format()))), 
            color = NA, 
            fill = "#C038A3",
            scale = 0.5, 
            side = "left") +
    scale_fill_ramp_discrete(from = "white",
                           range = c(1,0.25)) +
    stat_dotsinterval(scale = 0.5, 
                      fill = "#C038A3",
                    quantiles = 50, 
                    side = "right",
                    slab_color = NA,
                    show_point = FALSE,
                    show_interval = FALSE) +
  geom_point(data = JIF_new_agg,
             aes(x = year_split,
                 y = JIF),
             color = "black",
             size = 3) +
  labs(title = "A: Distribution of JIF",
       #subtitle = "for 2008-2009 (left) and 2018-2019 (right)",
       x = "",
       y = "Journal Impact Factor\n") +
  scale_y_continuous(breaks = c(0,1,2,3), 
                     limits = c(0,4)) +
  theme_minimal() +
  theme(
    legend.position = "none",
    plot.title = element_text(face = "bold",
                                       size = 14),
    plot.subtitle = element_text(size = 12),
    plot.title.position = "plot"
  )
```

```{r code-study-design}
DF$StudyType[DF$StudyType == ""] <- NA
```

```{r code-study-data}
DF$EmpiricalStudyData[DF$EmpiricalStudyData == ""] <- NA
# erin checked this multiple one 
DF$EmpiricalStudyData[DF$ArticleID == "86897574"] <- "Secondary" 

# update to new coding
DF$EmpiricalStudyData <- gsub("case study|observational study|correlational study|field study or language description|experimental study|survey or interview|^intervention|observation study|observational|observation|case studies|intervention studyt|intervention|interviews", "Primary", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- gsub("corpus study|^discourse|^meta|typological study|partly also discourse analysis|discourse analysis|corpus|description of archive of stuttered speech|secondary data from previous reports", "Secondary", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- gsub("^formal|modelling|^test battery.+|introspection", "Other", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- gsub("phonology|multiple study types reported|computational|study|with no systematically sampled material, just selected examples|simulation|could be .+|corpus|not language per se.+|-analysis|analysis", "", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- trimws(DF$EmpiricalStudyData)

DF$EmpiricalStudyData <- gsub(".*Primary.*", "Primary", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- gsub(".*Secondary.*", "Secondary", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- gsub(",|  ", " ", DF$EmpiricalStudyData)
```

```{r create-final-DF}
# filter down to only articles to include because of coding
#### created filtered data that is what we coded ----
DF_filtered <- DF %>% 
  filter(ArticleIssues == "There are no issues") %>% 
  filter(Agree == TRUE) 

# for the table
DF_filtered_ps <- DF_filtered %>% 
  #filter(EmpiricalStudyData != "Other") %>% 
  filter(StudyType == "Empirical data (specify the study type in the next step)")
```

```{r table1, results = 'asis', include = TRUE, echo = FALSE}
# Table 2
table1 <- data.frame(
  "Metric" = c("Coded Articles", "Included Articles", 
               "Number Journals", "Number Languages", 
               "JIF", "Number of Countries", 
               "Study Design - Empirical", 
               "Study Design - Not Empirical", 
               "Study Design - Meta-Analysis",
               "Study Data - Primary",
               "Study Data - Secondary",
               "Study Data - Other"), 
  ## total stats
  "Total" = c(
    nrow(DF), 
    nrow(DF_filtered),
    length(unique(DF$Source.title)), 
    length(unique(langDF$language)),
    paste(round(mean(JIF_new$JIF), 2), " (", round(sd(JIF_new$JIF), 2), ") ", 
          "Mdn = ", round(median(JIF_new$JIF),2), sep = ""),
    length(unique(DF$CountryAuthor)),
    sum(grepl("^Empirical", DF_filtered$StudyType)), 
    sum(grepl("^No empirical", DF_filtered$StudyType)), 
    sum(grepl("^Data", DF_filtered$StudyType)),
    sum(grepl("^Primary", DF_filtered_ps$EmpiricalStudyData)), 
    sum(grepl("^Second", DF_filtered_ps$EmpiricalStudyData)), 
    sum(grepl("^Other", DF_filtered_ps$EmpiricalStudyData))
    ),
  ## pre stats 
  "Pre-OS" = c(
    nrow(DF %>% filter(year_split == "Pre-OS")), 
    nrow(DF_filtered %>% filter(year_split == "Pre-OS")), 
    length(unique(DF$Source.title[DF$year_split == "Pre-OS"])),
    length(unique(langDF$language[langDF$year_split == "Pre-OS"])),
    paste(round(mean(JIF_new$JIF[JIF_new$year_split == "Pre-OS"]), 2), " (", round(sd(JIF_new$JIF[JIF_new$year_split == "Pre-OS"]), 2), ") ", 
          "Mdn = ", round(median(JIF_new$JIF[JIF_new$year_split == "Pre-OS"]),2), sep = ""),
    length(unique(DF$CountryAuthor[DF$year_split == "Pre-OS"])),
    sum(grepl("^Empirical", DF_filtered$StudyType[DF_filtered$year_split == "Pre-OS"])), 
    sum(grepl("^No empirical", DF_filtered$StudyType[DF_filtered$year_split == "Pre-OS"])), 
    sum(grepl("^Data", DF_filtered$StudyType[DF_filtered$year_split == "Pre-OS"])),
    sum(grepl("^Primary", DF_filtered_ps$EmpiricalStudyData[DF_filtered_ps$year_split == "Pre-OS"])), 
    sum(grepl("^Second", DF_filtered_ps$EmpiricalStudyData[DF_filtered_ps$year_split == "Pre-OS"])), 
    sum(grepl("^Other", DF_filtered_ps$EmpiricalStudyData[DF_filtered_ps$year_split == "Pre-OS"]))
    ),
  
  ## post stats 
  "After-OS" = c(
     nrow(DF %>% filter(year_split == "After-OS")),
     nrow(DF_filtered %>% filter(year_split == "After-OS")),
     length(unique(DF$Source.title[DF$year_split == "After-OS"])),
     length(unique(langDF$language[langDF$year_split == "After-OS"])),
     paste(round(mean(JIF_new$JIF[JIF_new$year_split == "After-OS"]), 2), " (", round(sd(JIF_new$JIF[JIF_new$year_split == "After-OS"]), 2), ") ", 
          "Mdn = ", round(median(JIF_new$JIF[JIF_new$year_split == "After-OS"]),2), sep = ""),
     length(unique(DF$CountryAuthor[DF$year_split == "After-OS"])),
     sum(grepl("^Empirical", DF_filtered$StudyType[DF_filtered$year_split == "After-OS"])), 
     sum(grepl("^No empirical", DF_filtered$StudyType[DF_filtered$year_split == "After-OS"])), 
     sum(grepl("^Data", DF_filtered$StudyType[DF_filtered$year_split == "After-OS"])),
     sum(grepl("^Primary", DF_filtered_ps$EmpiricalStudyData[DF_filtered_ps$year_split == "After-OS"])), 
     sum(grepl("^Second", DF_filtered_ps$EmpiricalStudyData[DF_filtered_ps$year_split == "After-OS"])), 
     sum(grepl("^Other", DF_filtered_ps$EmpiricalStudyData[DF_filtered_ps$year_split == "After-OS"]))
     )
)

apa_table(table1, 
          caption = "Sample Study Characteristics",
          note = "All values are raw counts on the original sample size, except JIF which represents the mean and standard deviation. Empirical study data type was categorized after examination of the results.")
```

```{r figure1, echo = FALSE, include = TRUE, fig.cap = "Figure 1. A: The proportion of first author affiliationâ€™s country binned into United Nations Subregions collapsing all Asian subregions together and all other non-visualized regions as the other category. B: The proportion of languages examined in these studies collapsing all other languages together. Cross Linguistic samples represented studies with five or more languages."}
# figure 1 
bar_countries + bar_languages + plot_layout(widths = c(3,3))

saved <- bar_countries + bar_languages + plot_layout(widths = c(3,3))
ggsave(filename = "figure/figure1.png",
       plot = saved, 
       device = "png",
       width = 8,
       height = 4,
       units = "in", 
       dpi = 500)
```

While the difference between articles published in our early and our late time window have similar sample properties, there are general noteworthy asymmetries in our sample. First and foremost, we notice a very strong anglocentric bias for both the host country of the corresponding author and the language under investigation, as shown in Figure 1. A large portion of studies are conducted with first author affiliations in the United States, United Kingdom, or Europe, and the primary language under investigation is English. While these properties may be tied to the sampling of English-written articles, these asymmetries quantify often articulated concerns that claims about human language are too often based on a small set of languages, limiting their generalisability (e.g. Majid & Levinson 2010, Goddard & Wierzbicka 2014, Levisen 2018).

Linguistics is a multidisciplinary field with many different empirical traditions. Our sample contained a wide variety of study types which we tried to categorize into three categories (empirical data, no empirical data, meta-analysis). From these categories, we attempted to label empirical data into seven proposed categories. Coding of these categories was often difficult due to a lack of clear-cut definitions between them. In order to describe the patterns observed in a digestible way, we will subsume study types into three super categories that are defined by the relationship between the data and the analysis: 1) Primary data defined as data collected during the study (including experimental studies, observational studies, correlational studies, field studies or language description, case studies, surveys, and interviews), 2) Secondary data defined as data from previous data collections or reanalysis (including corpus studies, descriptions of archives, discourse analyses, secondary data analyses from published data, typological studies), and 3) Other category which does not fit the former two definitions and for which most coded measures are irrelevant (modeling, simulations, introspections, formal linguistic analyses). After coding these values, we found very few Other category articles, but several articles that included multiple types of data. In order to ensure that count values were represented only once in the following descriptions, each was coded as Primary if it contained any Primary data, Secondary if it was coded as Secondary and Other, and Other was reserved for studies with only Other data. These counts can be found in Table 2. The Other category was excluded for analyses below that focused on primary and secondary data. 

Out of `r nrow(DF_filtered)` included articles in the study sample, `r nrow( DF_filtered %>% filter(EmpiricalStudyData != "Other") %>% filter(StudyType == "Empirical data (specify the study type in the next step)"))` reported study design with empirical data (Study Design - Empirical). The availability of materials, raw and processed data, and analysis was assessed only for the empirical study subsample. 

## 3.2 Article availability (open access)

```{r open-access}
A_ID_fix <- c("9.6498326E7", "9586644.0", "8.6897574E7",
              "3.5147373E7", "3.400467E7", "3.3442876E7",
              "5.3780209E7", "9.8056778E7", "9923056.0",
              "6.7395332E7", "5.84E59", "9.8963718E7",
              "2.0880301E7", "8.4326216E7", "3.0630572E7",
              "8.86E11")

A_ID_fix <- paste0("\\b", A_ID_fix, "\\b")
A_ID_fixed <- setdiff(DF_filtered$ArticleID, openaccessDF$ID)

openaccessDF$ID <- stri_replace_all_regex(str = openaccessDF$ID,
                             pattern = A_ID_fix, 
                             replacement = A_ID_fixed,
                             vectorize_all = FALSE)

A_ID_fixed <- setdiff(DF$ArticleID, openaccessDF$ID)
A_ID_fix <- c("1.5561653E7", "4160000.0")
A_ID_fix <- paste0("\\b", A_ID_fix, "\\b")
openaccessDF$ID <- stri_replace_all_regex(str = openaccessDF$ID,
                             pattern = A_ID_fix, 
                             replacement = A_ID_fixed,
                             vectorize_all = FALSE)


#### created filtered data that is only primary and secondary ----
DF_filtered_ps <- DF_filtered %>% 
  filter(EmpiricalStudyData != "Other") %>% 
  filter(StudyType == "Empirical data (specify the study type in the next step)")

openaccessDF_filtered <- openaccessDF %>% 
  filter(ID %in% DF_filtered_ps$ArticleID)

openaccessDF_all <- openaccessDF %>% 
  filter(ID %in% DF$ArticleID)
openaccessDF_used <- openaccessDF %>% 
  filter(ID %in% DF_filtered$ArticleID)
```

Among the `r nrow(DF_filtered_ps)` eligible empirical study data articles (primary and secondary), we obtained a publicly available version for `r sum(openaccessDF_filtered$open_access == "yes")` (`r round(sum(openaccessDF_filtered$open_access == "yes")/nrow(openaccessDF_filtered)*100, 1)`%), whereas `r sum(openaccessDF_filtered$open_access == "no")` (`r round(sum(openaccessDF_filtered$open_access == "no")/nrow(openaccessDF_filtered)*100, 1)`%) were only accessible through a paywall. `r sum(openaccessDF_filtered$open_access == "unknown")` (`r round(sum(openaccessDF_filtered$open_access == "unknown")/nrow(openaccessDF_filtered)*100, 1)`%) articles were not available at all. 

This rate was approximately the same when we examine the entire (*n* = `r nrow(openaccessDF_all)`) or coded (*n* = `r nrow(openaccessDF_used)`) datasets. For the entire dataset, `r sum(openaccessDF_all$open_access == "yes")` (`r round(sum(openaccessDF_all$open_access == "yes")/nrow(openaccessDF_all)*100, 1)`%) were available,  `r sum(openaccessDF_all$open_access == "no")` (`r round(sum(openaccessDF_all$open_access == "no")/nrow(openaccessDF_all)*100, 1)`%) were paywalled, and `r sum(openaccessDF_all$open_access == "unknown")` (`r round(sum(openaccessDF_all$open_access == "unknown")/nrow(openaccessDF_all)*100, 1)`%) were not available. For the coded dataset, `r sum(openaccessDF_used$open_access == "yes")` (`r round(sum(openaccessDF_used$open_access == "yes")/nrow(openaccessDF_used)*100, 1)`%) were available,  `r sum(openaccessDF_used$open_access == "no")` (`r round(sum(openaccessDF_used$open_access == "no")/nrow(openaccessDF_used)*100, 1)`%) were paywalled, and `r sum(openaccessDF_used$open_access == "unknown")` (`r round(sum(openaccessDF_used$open_access == "unknown")/nrow(openaccessDF_used)*100, 1)`%) were not available.


## 3.3 Materials availability

```{r code-materials}
# clean up materials only primary and secondary 
DF_filtered_ps$Materials[DF_filtered_ps$Materials == ""] <- NA
DF_filtered_ps$Materials <- sub(".*dead.*", "Yes, materials or additional information about the method are freely available", DF_filtered_ps$Materials)
DF_filtered_ps$Materials <- sub(" \\(GO TO SECTION 7\\)", "", DF_filtered_ps$Materials)
DF_filtered_ps$Materials <- sub(".*Not applicable.*", NA, DF_filtered_ps$Materials)
DF_filtered_ps$Materials <- sub(".*Supplementary.*|.*Append.*|.*append.*|.+supplementary.+", "Yes, materials or additional information about the method are freely available
", DF_filtered_ps$Materials)
DF_filtered_ps$Materials <- sub(".*third.*|Links to online corpora provided", "Yes, materials or additional information about the method are freely available", DF_filtered_ps$Materials)
DF_filtered_ps$Materials <- trimws(DF_filtered_ps$Materials)

DF_filtered_ps$Materials <- factor(DF_filtered_ps$Materials,
                                levels = names(table(DF_filtered_ps$Materials)), 
                                labels = c("not available", "available"))

# clean up where 
DF_filtered_ps$MaterialsWhere[DF_filtered_ps$MaterialsWhere == ""] <- NA
DF_filtered_ps$MaterialsWhere <- gsub(".*brok.*|.*dead.*|Dead.*|.*porn.*", "Dead Links", DF_filtered_ps$MaterialsWhere)
DF_filtered_ps$MaterialsWhere <- gsub(".*Suppl.*", "Supplement", DF_filtered_ps$MaterialsWhere)
DF_filtered_ps$MaterialsWhere <- gsub(".*append.*|.*Append.*|In the actual article", "Appendix", DF_filtered_ps$MaterialsWhere)
DF_filtered_ps$MaterialsWhere <- gsub(".*third.*", "Third-Party", DF_filtered_ps$MaterialsWhere)
DF_filtered_ps$MaterialsWhere <- gsub(".*some materials.*|.*Some materials.*|.*Some avail.*", "Partial Materials", DF_filtered_ps$MaterialsWhere)
DF_filtered_ps$MaterialsWhere <- gsub("Authors state materials.*|Upon request.*", "Other", DF_filtered_ps$MaterialsWhere)
DF_filtered_ps$MaterialsWhere <- gsub("Personal or institutional website", "Website", DF_filtered_ps$MaterialsWhere)

# summarize materials 
materials_graph <- DF_filtered_ps %>% 
  filter(!is.na(Materials)) %>% 
  group_by(year_split, EmpiricalStudyData, Materials) %>% 
  summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split, EmpiricalStudyData) %>% 
  mutate(prop = round(n / sum(n)*100, 1)) 

materials_access <- DF_filtered_ps %>% 
  filter(!is.na(Materials)) %>% 
  group_by(year_split, EmpiricalStudyData, Materials) %>% 
  summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split, EmpiricalStudyData) %>% 
  mutate(prop = round(n / sum(n)*100, 1)) %>% 
  filter(Materials == "available")

materials_where <- DF_filtered_ps %>% 
  filter(Materials == "available") %>% 
  group_by(MaterialsWhere) %>% 
  summarize(n = n()) %>% 
  mutate(prop = round(n / sum(n)*100, 1))
```

Data for articles containing primary and secondary data are visualized in Figure 2. Of those articles published in 2008/2009 and involving primary data, `r materials_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Primary") %>% pull(n)` (`r materials_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Primary") %>% pull(prop)`%) contained a statement or link regarding the availability of original research materials such as survey instruments, software, or stimuli. Of those articles involving secondary data, `r materials_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Secondary") %>% pull(n)` (`r materials_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Secondary") %>% pull(prop)`%) articles contained such a statement or link. Of those articles published in 2018/2019 and involving primary data, `r materials_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Primary") %>% pull(n)` (`r materials_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Primary") %>% pull(prop)`%) contained such a statement or link. Of those articles involving secondary data, `r materials_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Secondary") %>% pull(n)` (`r materials_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Secondary") %>% pull(prop)`%) articles contained such a statement or link.

For the `r sum(materials_where$n)` articles for which materials were reportedly available, the materials were not actually available for `r materials_where %>% filter(MaterialsWhere == "Dead Links") %>% pull(n)` articles because of broken links. For the `r sum(materials_where$n) - materials_where %>% filter(MaterialsWhere == "Dead Links") %>% pull(n)` articles that we could access, the materials were made available in the article itself (e.g., in a table or appendix; *n* = `r materials_where %>% filter(MaterialsWhere == "Appendix") %>% pull(n)`), in a journal-hosted supplement (*n* = `r materials_where %>% filter(MaterialsWhere == "Supplement") %>% pull(n)`), on a personal or institutionally hosted (nonrepository) webpage (*n* = `r materials_where %>% filter(MaterialsWhere == "Website") %>% pull(n)`), or in an online third-party repository (*n* = `r materials_where %>% filter(MaterialsWhere == "Third-Party") %>% pull(n)`). All other materials locations were coded as other. 

## 3.4 Data availability

### Raw data

```{r code-rawdata}
# clean up raw data
DF_filtered_ps$RawData[DF_filtered_ps$RawData == ""] <- NA
DF_filtered_ps$RawData <- sub("Individual examples of linguistic phenomenon >> text files\\?", "Text file", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub("Not applicable, Examples of analyzed sentences provided in article text", "Not applicable", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub("Not applicable, Examples of sentences in text \\(syntactic analysis\\)", "Not applicable", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub('^survey results.*', "Text file", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub("single examples", "Text file", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub(", Answers obtained from stimuli items", "", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub(", Survey responses", "", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub(", individual examples in article >> text files\\?", "", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub(', results of experiment with reaction times.*', "", DF_filtered_ps$RawData)
DF_filtered_ps$RawData <- sub(", online corpus", "", DF_filtered_ps$RawData)

# create a dataframe of long format
dataDF <- DF_filtered_ps %>% 
  select(RawData, year_split, ArticleID, EmpiricalStudyData) %>% 
  separate(RawData, sep = ",", into = c("A", "B", "C"), 
           extra = "warn") %>% 
  pivot_longer(cols = c(A,B, C)) %>% 
  filter(!is.na(value)) %>% 
  select(year_split, value, ArticleID, EmpiricalStudyData) %>% 
  rename(data = value) %>% 
  filter(data != "")

# the dumb hack
dataDF$data <- gsub("[^[:alnum:]]", "9", dataDF$data)
dataDF$data <- gsub("^9+(.+)", "\\1", dataDF$data)
dataDF$data <- gsub("(.+)9+$", "\\1", dataDF$data)
dataDF$data <- gsub("9", " ", dataDF$data)

# create a summary of the data 
rawdata_types <- dataDF %>% 
  group_by(data, year_split, EmpiricalStudyData) %>% 
  summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split, EmpiricalStudyData) %>% 
  mutate(prop = round(n / sum(n)*100, 1)) %>% 
  group_by(data) %>% 
  mutate(overall = sum(n), 
         prop_overall = sum(n) / nrow(dataDF))

# code availability of raw data
DF_filtered_ps$RawDataAvl[DF_filtered_ps$RawDataAvl == ""] <- NA
DF_filtered_ps$RawDataAvl <- sub(".*corp.*|^Corpus.*", "available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl <- sub("No statement but links to data sources|Raw data \\(examples\\) are provided within the publication", "available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl <- sub(".*third.*", "available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl <- sub("State that the data is no longer available", "not available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl <- sub("Some raw data available", "available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl <- sub("No, raw data.*", "not available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl <- sub("^Yes.*", "available", DF_filtered_ps$RawDataAvl)
DF_filtered_ps$RawDataAvl[!is.na(DF_filtered_ps$EmpiricalStudyData) & is.na(DF_filtered_ps$RawDataAvl)] <- "not available"

# create a summary of the data 
rawdata_graph <- DF_filtered_ps %>% 
  group_by(RawDataAvl, year_split, EmpiricalStudyData) %>% 
  summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split, EmpiricalStudyData) %>% 
  mutate(prop = round(n / sum(n)*100, 1))

rawdata_access <- rawdata_graph %>% filter(RawDataAvl == "available")

# save upon request
total_data_upon <- sum(grepl("request", DF_filtered_ps$RawDataWhere))

# raw data access
DF_filtered_ps$RawDataWhere[DF_filtered_ps$RawDataWhere == ""] <- NA
DF_filtered_ps$RawDataWhere <- gsub(".*as part of the.*|^Supplementary.*|.*in the article.*", "Supplemental" , DF_filtered_ps$RawDataWhere)
DF_filtered_ps$RawDataWhere <- gsub(".*Blog.*|^Personal.*", "Personal" , DF_filtered_ps$RawDataWhere)
DF_filtered_ps$RawDataWhere <- gsub(".*Corpus.*|.*corpus.*|.*third-party.*|.*third party.*", "Third-Party" , DF_filtered_ps$RawDataWhere)
DF_filtered_ps$RawDataWhere <- gsub(".*request.*|.*not work.*|.*no longer.*|.*Unclear.*", "Dead" , DF_filtered_ps$RawDataWhere)
```


Raw data was defined as recorded information in its rawest, digital form, at the level of sampling units (e.g., participants, words, utterances, trials, etc.). Data for raw data for articles containing primary and secondary data are visualized in Figure 2. Each article could include multiple data types, and therefore, `r nrow(DF_filtered_ps)` articles produced `r nrow(dataDF)` unique data types included in the article, and most frequently, these data were coded as text files. 


Of those articles published in 2008/2009 and involving primary data, `r rawdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Primary") %>% pull(n)` (`r rawdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Primary") %>% pull(prop)`%) contained a statement or link regarding the availability of raw data such as audio recordings, transcriptions or data provided by experimental software. Of those articles involving secondary data, `r rawdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Secondary") %>% pull(n)` (`r rawdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Secondary") %>% pull(prop)`%) articles contained such a statement or link. Of those articles published in 2018/2019 and involving primary data, `r rawdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Primary") %>% pull(n)` (`r rawdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Primary") %>% pull(prop)`%) contained such a statement or link. Of those articles involving secondary data, `r rawdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Secondary") %>% pull(n)` (`r rawdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Secondary") %>% pull(prop)`%) articles contained such a statement or link.

For the `r nrow(DF_filtered_ps %>% filter(!is.na(RawDataWhere)))` articles for which raw data were reportedly available, the data were not actually available for `r nrow(DF_filtered_ps %>% filter(RawDataWhere == "Dead"))` articles because of broken links or availability "upon request". For the articles that we could access, the raw data were made available in a journal-hosted supplement (*n* = `r nrow(DF_filtered_ps %>% filter(RawDataWhere == "Supplemental"))`), on a personal or institutionally hosted (nonrepository) webpage (*n* = `r nrow(DF_filtered_ps %>% filter(RawDataWhere == "Personal"))`), or in an online third-party repository (*n* = `r nrow(DF_filtered_ps %>% filter(RawDataWhere == "Third-Party"))`). Of those articles, `r nrow(DF_filtered_ps %>% filter(RawDataDocument == "Yes"))` data sources were documented.

### Derived data

```{r code-processed}
# clean up processed data
DF_filtered_ps$ProcessData[DF_filtered_ps$ProcessData == ""] <- NA
DF_filtered_ps$ProcessData <- sub("^No.*|^Points.*", "not available", DF_filtered_ps$ProcessData)
DF_filtered_ps$ProcessData <- sub("^Yes.*|.*raw data.*", "available", DF_filtered_ps$ProcessData)
DF_filtered_ps$ProcessData[is.na(DF_filtered_ps$ProcessData) & !is.na(DF_filtered_ps$EmpiricalStudyData)] <- "not available"

# create a summary of the data 
processdata_graph <- DF_filtered_ps %>% 
  group_by(ProcessData, year_split, EmpiricalStudyData) %>% 
  summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split, EmpiricalStudyData) %>% 
  mutate(prop = round(n / sum(n)*100, 1))

processdata_access <- processdata_graph %>% filter(ProcessData == "available")

DF_filtered_ps$ProcessDataWhere[DF_filtered_ps$ProcessDataWhere == ""] <- NA
DF_filtered_ps$ProcessDataWhere <- gsub("^Personal.*", "Personal" , DF_filtered_ps$ProcessDataWhere)
DF_filtered_ps$ProcessDataWhere <- gsub(".*third-party.*|.*third party.*", "Third-Party" , DF_filtered_ps$ProcessDataWhere)
DF_filtered_ps$ProcessDataWhere <- gsub(".*request.*|.*doesn't work.*|.*no longer.*|.*Unclear.*", "Dead" , DF_filtered_ps$ProcessDataWhere)
DF_filtered_ps$ProcessDataWhere <- gsub("^Supplementary.*", "Supplemental" , DF_filtered_ps$ProcessDataWhere)
```

Derived data was defined as a derived form of the data that has undergone changes from its raw state (e.g., extraction of acoustic parameters via Praat, aggregates of responses, etc.). Data for derived data for articles containing primary and secondary data are visualized in Figure 2. Of those articles published in 2008/2009 and involving primary data, `r processdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Primary") %>% pull(n)` (`r processdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Primary") %>% pull(prop)`%) contained a statement or link regarding the availability of derived data such as audio recordings, transcriptions or data provided by experimental software. Of those articles involving secondary data, `r processdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Secondary") %>% pull(n)` (`r processdata_access %>% filter(year_split == "Pre-OS" & EmpiricalStudyData == "Secondary") %>% pull(prop)`%) articles contained such a statement or link. Of those articles published in 2018/2019 and involving primary data, `r processdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Primary") %>% pull(n)` (`r processdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Primary") %>% pull(prop)`%) contained such a statement or link. Of those articles involving secondary data, `r processdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Secondary") %>% pull(n)` (`r processdata_access %>% filter(year_split == "After-OS" & EmpiricalStudyData == "Secondary") %>% pull(prop)`%) articles contained such a statement or link.

For the `r sum(processdata_access$n)`  articles for which derived data were reportedly available, the data were not actually available for `r nrow(DF_filtered_ps %>% filter(ProcessDataWhere == "Dead"))` articles because of broken links or availability "upon request". For the articles that we could access, the derived data were made available in a journal-hosted supplement (*n* = `r nrow(DF_filtered_ps %>% filter(ProcessData == "available" & ProcessDataWhere == "Supplemental"))`), on a personal or institutionally hosted (nonrepository) webpage (*n* = `r nrow(DF_filtered_ps %>% filter(ProcessDataWhere == "Personal"))`), or in an online third-party repository (*n* = `r nrow(DF_filtered_ps %>% filter(ProcessDataWhere == "Third-Party"))`). Of those articles, `r nrow(DF_filtered_ps %>% filter(ProcessDataDocument == "Yes"))` data sources were documented.

## 3.5 Analysis-script availability

```{r code-analysis}
DF_filtered_ps$AnalysisScript[DF_filtered_ps$AnalysisScript == ""] <- NA
DF_filtered_ps$AnalysisScript <- sub("^No.*|^Analysis.*|^Link.*", "not available", DF_filtered_ps$AnalysisScript)
DF_filtered_ps$AnalysisScript <- sub("^Yes.*", "available", DF_filtered_ps$AnalysisScript)
DF_filtered_ps$AnalysisScript[!is.na(DF_filtered_ps$EmpiricalStudyData) & is.na(DF_filtered_ps$AnalysisScript)] <- "not available"

# create a summary of the data 
analysis_graph <- DF_filtered_ps %>% 
  group_by(AnalysisScript, year_split, EmpiricalStudyData) %>% 
  summarize(n = n(), .groups = "keep") %>% 
  group_by(year_split, EmpiricalStudyData) %>% 
  mutate(prop = round(n / sum(n)*100, 1))
```

Of the `r nrow(DF_filtered_ps)` articles that involved primary or secondary data, an analysis script was shared for `r nrow(DF_filtered_ps %>% filter(AnalysisScript == "available"))` articles (`r round(nrow(DF_filtered_ps %>% filter(AnalysisScript == "available"))/nrow(DF_filtered_ps)*100,1)`%). The scripts were made available in a journal-hosted supplement (*n* = `r nrow(DF_filtered_ps %>% filter(grepl("^Code|^Suppl", AnalysisScriptWhere)))`), or in an online third-party repository (*n* = `r nrow(DF_filtered_ps %>% filter(grepl("^An online", AnalysisScriptWhere)))`).

## 3.6 Preregistration

No articles across all coded articles (*n* = `r nrow(DF_filtered)`) was preregistered.

## 3.7 Replication

Of the `r nrow(DF_filtered_ps)` articles that were experimental, `r nrow(DF_filtered_ps %>% filter(grepl("claims to report", Replication))) - 1` articles (`r round((nrow(DF_filtered_ps %>% filter(grepl("claims to report", Replication)))-1)/nrow(DF_filtered_ps)*100,1)`%) were replications according to the definition used in Kobrock & Roettger (2022): "We first searched for the search string "replic*" and if we got a hit, we examined title and abstract of the paper, text before and after occurrences of the search term replicat*, the paragraph before the Methods section as well as the first paragraph of the Discussion section. If the authors explicitly claimed that (one of) their research aim(s) was to replicate the result or methods of an initial study, this article was treated as a replication." Following Marsden et al. (2018), replication studies were classified according to the number of changes made into three categories: direct replication (0 changes), partial replication (1 change) and conceptual replication (2 or more changes). Of those that were classified as replications, all four were conceptual replications. 

## 3.8 Conflict-of-interest statements

Of the `r nrow(DF_filtered)` coded articles, `r nrow(DF_filtered %>% filter(grepl("Yes", COI)))` included a statement about conflicts-of-interest (`r round(nrow(DF_filtered %>% filter(grepl("Yes", COI)))/nrow(DF_filtered)*100, 1)`%). All of these articles stated that there was no conflict of interest. 

```{r figure2, echo = FALSE, include = TRUE, fig.cap = "Figure 2. Percentages of the availability of materials, raw data, processed data, and analysis scripts for Pre-RC (before acknowledgement of replication crisis, left) and Post-RC (after acknowledgement, right)."}
# combine everything
fig2_data <- bind_rows(
  materials_graph %>% 
    mutate(Measure = paste("Materials - ", Materials, sep = "")) %>% 
    na.omit(), 
  rawdata_graph %>% 
    mutate(Measure = paste("Raw Data - ", RawDataAvl, sep = "")) %>% 
    na.omit(), 
  processdata_graph %>% 
    mutate(Measure = paste("Processed Data - ", ProcessData, sep = "")) %>% 
    na.omit(), 
  analysis_graph %>% 
    mutate(Measure = paste("Analysis - ", AnalysisScript, sep = "")) %>% 
    na.omit()
  ) %>% 
  separate(Measure, sep = "-", 
           into = c("Type", "available"), 
           remove = FALSE,
           extra = "warn")

# reorder pre and post
fig2_data$year_split <- factor(fig2_data$year_split, 
                               levels = c("Pre-OS", "After-OS"))

# ggplot(fig2_data, aes(EmpiricalStudyData, prop, fill = available)) + 
#   geom_bar(stat = "identity", position = "stack", color = "black") + 
#   theme_classic() +
#   facet_wrap(~Type*year_split, ncol = 2, labeller=function(x) {x[1]}) +
#   xlab("Empirical Study Data Type") + 
#   ylab("Proportion") + 
#   coord_flip()

# TRs suggestion
fig2_data2 <- fig2_data %>%
  mutate(year_split = factor(year_split, 
            levels = c("Pre-OS", "After-OS")),
         EmpiricalStudyData = factor(EmpiricalStudyData, 
            levels = c("Secondary", "Primary")),
         available = factor(available, 
            levels = c(" available", " not available"),
            labels = c(" Available", " Not available")),
         Type = as.factor(Type),
         Type = factor(Type, 
            levels = c("Materials ", "Raw Data ", "Processed Data ", "Analysis "))
       )

levels(fig2_data2$year_split) <- c("Pre-RC (2008/09)", "Post-RC (2018/2019)")

fig2_data_label <- fig2_data2 %>%
  mutate(label = paste0(round(prop,0), "% ", "(n = ", n, ")"),
         label = ifelse(available != " Available", label, ""),
         label2 = ifelse(prop > 10 & available == " Available", paste0(round(prop,0), "%"), "")
       )

# plot
fig2 <- 
ggplot(fig2_data2, aes(y = EmpiricalStudyData, 
                       x = prop, 
                       col = available,
                       fill = available)) + 
  geom_col(position = "stack", 
           color = "black", 
           size = 0.05) + 
  geom_text(data = fig2_data_label,
            aes(label = label),
            x = 10,
            hjust = 0,
            cex = 5) +
  geom_text(data = fig2_data_label,
            aes(label = label2),
            x = 98,
            hjust = 1,
            cex = 5) +
  facet_grid(Type ~ year_split) +
  labs(title = "Assessment of transparency-related research practices in linguistics",
       subtitle = "",
       x = "\n Proportion in %",
       y = "",
       fill = "") +
  guides(color = "none",
         fill = guide_legend(reverse = TRUE)) +
  scale_color_manual(values = c("black", "black")) +
  scale_fill_manual(values = c("#66c2a5", "#bbb5b7")) +
  scale_x_continuous(limits = c(0, 100),
                     expand = c(0,0),
                     breaks = c(0,20,40,60,80,100),
                     labels = c("0%","20%","40%","60%","80%","100%")) +
  theme_classic() +
  theme(legend.position = "bottom",
        strip.background = element_blank(),
        axis.title.y = element_blank(),
        title = element_text(size = 14,
                             face = "bold"),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(size = 12),
        strip.text.x = element_text(size = 14, 
                                    hjust = 0.5,
                                    face = "bold"),
        strip.text.y = element_text(size = 12,
                                    angle = 0,
                                    hjust = 0,
                                    face = "bold"),
        legend.title = element_text(size = 12,
                                    face = "bold"),
        legend.text=element_text(size = 12),

        panel.background = element_rect(fill = 'white'),
        panel.spacing.x = unit(2, "lines"),
        panel.spacing.y = unit(1.5, "lines")
    )

ggsave(filename = "figure/figure2.png",
       plot = fig2,
       device = "png",
       width = 240, 
       height = 140,
       units = "mm", 
       bg='#ffffff',
       dpi = 500)

# alternative color scheme

fig2_data2 <- fig2_data %>%
  mutate(year_split = factor(year_split, 
            levels = c("Pre-OS", "After-OS")),
         EmpiricalStudyData = factor(EmpiricalStudyData, 
            levels = c("Secondary", "Primary")),
         available = factor(available, 
            levels = c(" available", " not available"),
            labels = c(" Available", " Not available")),
         Type = as.factor(Type),
         Type = factor(Type, 
            levels = c("Materials ", "Raw Data ", "Processed Data ", "Analysis "))
       )

levels(fig2_data2$year_split) <- c("Pre-RC (2008/09)", "Post-RC (2018/2019)")

fig2_data_label <- fig2_data2 %>%
  mutate(label = paste0(round(prop,0), "% ", "(n = ", n, ")"),
         label = ifelse(available != " Available", label, ""),
         label2 = ifelse(prop > 10 & available == " Available", paste0(round(prop,0), "%"), "")
       )

# plot
fig2b <- 
ggplot(fig2_data2, aes(y = EmpiricalStudyData, 
                       x = prop, 
                       col = available,
                       fill = available)) + 
  geom_col(position = "stack", 
           color = "black", 
           size = 0.05) + 
  geom_text(data = fig2_data_label,
            aes(label = label),
            x = 10,
            hjust = 0,
            cex = 5) +
  geom_text(data = fig2_data_label,
            aes(label = label2),
            x = 98,
            hjust = 1,
            cex = 5) +
  facet_grid(Type ~ year_split) +
  labs(title = "Assessment of transparency-related research practices in linguistics",
       subtitle = "",
       x = "\n Proportion in %",
       y = "",
       fill = "") +
  guides(color = "none",
         fill = guide_legend(reverse = TRUE)) +
  scale_color_manual(values = c("black", "black")) +
  scale_fill_manual(values = c("#4dac26", "#f1b6da")) +
  scale_x_continuous(limits = c(0, 100),
                     expand = c(0,0),
                     breaks = c(0,20,40,60,80,100),
                     labels = c("0%","20%","40%","60%","80%","100%")) +
  theme_classic() +
  theme(legend.position = "bottom",
        strip.background = element_blank(),
        axis.title.y = element_blank(),
        title = element_text(size = 14,
                             face = "bold"),
        axis.line = element_blank(),
        axis.ticks = element_blank(),
        axis.text = element_text(size = 12),
        strip.text.x = element_text(size = 14, 
                                    hjust = 0.5,
                                    face = "bold"),
        strip.text.y = element_text(size = 12,
                                    angle = 0,
                                    hjust = 0,
                                    face = "bold"),
        legend.title = element_text(size = 12,
                                    face = "bold"),
        legend.text=element_text(size = 12),

        panel.background = element_rect(fill = 'white'),
        panel.spacing.x = unit(2, "lines"),
        panel.spacing.y = unit(1.5, "lines")
    )

ggsave(filename = "figure/figure2b.png",
       plot = fig2b,
       device = "png",
       width = 300, 
       height = 150,
       units = "mm", 
       bg='#ffffff',
       dpi = 500)
```

## Discussion

```{r disc-numbers}
# materials
round(table(DF_filtered_ps$Materials, useNA = "ifany") / nrow(DF_filtered_ps) * 100, 1)

round(table(DF_filtered_ps$Materials, DF_filtered_ps$EmpiricalStudyData, useNA = "ifany") / nrow(DF_filtered_ps) * 100, 1)

round(table(DF_filtered_ps$Materials, DF_filtered_ps$year_split, useNA = "ifany") / nrow(DF_filtered_ps) * 100, 1)

# data
round(table(DF_filtered_ps$RawDataAvl, DF_filtered_ps$EmpiricalStudyData, useNA = "ifany") / nrow(DF_filtered_ps) * 100, 1)

total_data_upon

# language
round(table(langDF$language, useNA = "ifany") / nrow(langDF) * 100, 1)

# country
table(DF_filtered$CountryAuthor, useNA = "ifany")
round(table(DF_filtered$CountryAuthor, useNA = "ifany") / nrow(DF_filtered) * 100, 1)

# that english thing
langDF$compare <- "other"
langDF$compare[langDF$language == "english"] <- "english"
langDF$compare[langDF$language %in% c("german", "dutch", "danish", 
                                      "norwegian", "swedish", "french", 
                                      "spanish", "italian", "catalan", 
                                      "polish", "czech", "russian")] <- "indo"
table(langDF$compare) / nrow(langDF) * 100
```

```{r fig2-numbers, echo = T, include = T}
# overall statistics calculated by year, study data type, type of transparency measure 
fig2_data2 %>% 
  select(year_split, EmpiricalStudyData, Type, n, prop, available) %>% 
  print(., n = nrow(fig2_data2))

# statistics calculated by year, type of transparency measure (summed over study data type)
fig2_data2 %>% 
  group_by(year_split, Type, available) %>% 
  summarise(total_n = sum(n), .groups = "keep") %>% 
  group_by(year_split, Type) %>% 
  mutate(total_prop = total_n / sum(total_n) * 100)

# statistics calculated by study data type, transparency measured (summed over years) 
fig2_data2 %>% 
  group_by(EmpiricalStudyData, Type, available) %>% 
  summarise(total_n = sum(n), .groups = "keep") %>% 
  group_by(EmpiricalStudyData, Type) %>% 
  mutate(total_prop = total_n / sum(total_n) * 100)

# statistics calculated by study data type (summed over transparency measures and years )
fig2_data2 %>% 
  group_by(Type, available) %>% 
  summarise(total_n = sum(n), .groups = "keep") %>% 
  group_by(Type) %>% 
  mutate(total_prop = total_n / sum(total_n) * 100)

# open access statistics after fixing coding issues on the initial dataset (n = 600) by year 
openaccessDF_all %>% 
  group_by(open_access, year_split) %>% 
  summarize(total_n = n(), .groups = "keep") %>% 
  group_by(year_split) %>% 
  mutate(open_prop = total_n / sum(total_n) * 100)

# open access statistics on the included dataset (n = 519) by year 
openaccessDF_used %>% 
  group_by(open_access, year_split) %>% 
  summarize(total_n = n(), .groups = "keep") %>% 
  group_by(year_split) %>% 
  mutate(open_prop = total_n / sum(total_n) * 100)

# open access statistics on the included articles reporting empirical studies (n = 360) by year
openaccessDF_filtered %>% 
  group_by(open_access, year_split) %>% 
  summarize(total_n = n(), .groups = "keep") %>% 
  group_by(year_split) %>% 
  mutate(open_prop = total_n / sum(total_n) * 100)

# replication statistics on the included articles reporting empirical studies (n = 360) by year
# note that we double checked these and one was not a replication study and was miscoded 
DF_filtered_ps$Replication[DF_filtered_ps$Replication == ""] <- "There is no clear statement that the article reports a replication study (or studies)"
DF_filtered_ps %>% 
  group_by(Replication, year_split) %>% 
  summarize(total_n = n(), .groups = "keep") 

# coi statistics on the included dataset (n = 519) by year 
DF_filtered$COI[DF_filtered$COI == ""] <- "No, there is no conflict of interest statement"
DF_filtered %>% 
  group_by(COI, year_split) %>% 
  summarize(total_n = n(), .groups = "keep") %>% 
  group_by(COI) %>% 
  mutate(COI_prop = total_n / sum(total_n) * 100)
```


