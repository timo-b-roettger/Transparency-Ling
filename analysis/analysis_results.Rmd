---
title: "Transparency Linguistics Analysis"
author: "Erin M. Buchanan"
date: "Last Knitted `r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analysis Plan

For each measured variable, we will report raw numbers and percentages in each response category. Additional analyses will be exploratory; we are not conducting confirmatory tests of any a priori hypotheses.

## Libraries

```{r}
library(rio)
library(dplyr)
library(stringi)
library(tidyr)
library(psych)
library(ggplot2)
library(maps)
library(countrycode)
library(webr)
library(patchwork)

```

## Get the Data

```{r}
DF <- import("coded_responses.xlsx")
#DF <- import("analysis/coded_responses.xlsx")
# names(DF)

# column 35 is empty
DF <- DF %>% select(-`...35`)

# take out pilot testing 2021-05-21 04:12:04 and before
DF <- DF %>% filter(Timestamp > as.POSIXct("2021-05-22"))

# these names are descriptive but no fun to type
colnames(DF) <- c("TimeStamp", "TimeStarted", "DateStarted", 
                  "Coder", "ArticleID", "ArticleIssues", "ArticleLanguage", 
                  "JIF", "StudyType", "PreReg", "PreRegWhere", "PreRegAccess", 
                  "PreRegAspects", "RawData", "RawDataAvl", "RawDataWhere", 
                  "RawDataAccess", "RawDataDocument", "ProcessData", 
                  "ProcessDataWhere", "ProcessDataAccess", "ProcessDataDocument", 
                  "AnalysisScript", "AnalysisScriptWhere", "AnalysisScriptAccess",
                  "Materials", "MaterialsWhere", "MaterialsAccess", "COI", 
                  "Replication", "OA", "TimeEnded", "DateEnded", "CountryAuthor", 
                  "EmpiricalStudyData", "JIFYear")

# list of information from scopus
prescreenDF <- import("../Prescreening/prescreening_round1.csv")
prescreenDF2 <- import("../data/prescreening_list_2021-07-04.txt")

#prescreenDF <- import("Prescreening/prescreening_round1.csv")
#prescreenDF2 <- import("data/prescreening_list_2021-07-04.txt")

# deal with the duplicate ID issue 
# we didn't code this one but we did code the other one
# as per github page (pulled original number)
prescreenDF$ID[prescreenDF$Title == "Quantified epistemic logics for reasoning about knowledge in multi-agent systems"] <- "e754dd1b"

# import the OA code
openaccessDF <- import("OA_Coding_10_2021.xlsx") %>% select(-`...9`) %>% filter(!is.na(row_num))
#openaccessDF <- import("analysis/OA_Coding_10_2021.xlsx") %>% select(-`...9`) %>% filter(!is.na(row_num))

# import code on who was doing what to check all are done
coder1 <- import("../data/randomized_prescreen_df_2021_10_21.csv")
coder2 <- import("../data/randomized_prescreen_df_rnd2_2022_03_14.csv") 

#coder1 <- import("data/randomized_prescreen_df_2021_10_21.csv")
#coder2 <- import("data/randomized_prescreen_df_rnd2_2022_03_14.csv") 
```

### Clean Up Data

```{r}
# merge information about publication year, field, pre versus post 
DF2 <- DF %>% 
  # year, year label, DOI
  left_join(
  (prescreenDF %>% select(ID, Year, year_split, clickable_doi, first_code_include)), 
  by = c("ArticleID" = "ID")
) 
  
# fix the coding issues
A_ID_fix <- DF2 %>% filter(is.na(year_split)) %>% select(ArticleID) 
A_ID_fix <- as.vector(A_ID_fix$ArticleID)
A_ID_fix <- paste0("\\b", A_ID_fix, "\\b")

A_ID_fixed <- c("96498326", "9586644", "86897574", "35147373", 
                "34004670", "33442876", "53780209", "15561653", 
                "4.16E+06", "98056778", "74a007fe", "9923056", 
                "67395332", "5.84E+59", "98963718", "20880301",
                "84326216", "30630572", "8.86E+11", "15561653", 
                "239b8bc4", "98963718", "86897574")

length(A_ID_fix) == length(A_ID_fixed)

DF$ArticleID <- stri_replace_all_regex(str = DF$ArticleID,
                             pattern = A_ID_fix, 
                             replacement = A_ID_fixed,
                             vectorize_all = FALSE)

# fix some other fun quirks
# i checked these were not also in coder 2 
coder1$ID[coder1$ID == "8.86e+11"] <- "8.86E+11"
coder1$ID[coder1$ID == "5.84e+59"] <- "5.84E+59"
coder1$ID[coder1$ID == "4160000"] <- "4.16E+06"

# now really merge once IDs are fixed
DF2 <- DF %>% left_join(
  (prescreenDF %>% select(ID, Year, year_split, clickable_doi)), 
  by = c("ArticleID" = "ID")
) %>% 
  # coder assignments 
  full_join(
  (coder1 %>% select(ID, coder)), 
  by = c("ArticleID" = "ID")
) %>% 
  full_join(
  (coder2 %>% select(ID, round2_coder)),
  by = c("ArticleID" = "ID")
  ) %>% 
  # article journal, source title
  left_join(
    (prescreenDF2 %>% select(ID, Source.title)), 
     by = c("ArticleID" = "ID")
  )

# look for missing articles 
DF2 %>% filter(is.na(TimeStamp)) %>% select(coder, ArticleID)

# look at duplicates by the same person 
dup_IDs <- DF2 %>% filter(duplicated(DF2 %>% select(ArticleID, Coder))) %>% pull(ArticleID)

DF2 %>% filter(ArticleID %in% dup_IDs)

# now, what I did was go to the git issue
# https://github.com/troettge/Transparency-Ling/issues/24
# looked at the articles each person did
# figured out which two were copy paste article errors for TR
# LK appears to be a real duplicate 
# TR cc497581 also appears to be a real duplicate 

# 0e3e42b8 comes after 64cf897b
DF$ArticleID[DF$ArticleID == "64cf897b"][2] <- "0e3e42b8"

# remove real duplicates 
DF <- DF %>% 
  filter(!duplicated(DF %>% select(ArticleID, Coder)))

# final data 
DF <- DF %>% left_join(
  (prescreenDF %>% select(ID, Year, year_split, clickable_doi)), 
  by = c("ArticleID" = "ID")
) %>% 
  # coder assignments 
  full_join(
  (coder1 %>% select(ID, coder)), 
  by = c("ArticleID" = "ID")
) %>% 
  full_join(
  (coder2 %>% select(ID, round2_coder)),
  by = c("ArticleID" = "ID")
  ) %>% 
  # article journal, source title
  left_join(
    (prescreenDF2 %>% select(ID, Source.title)), 
     by = c("ArticleID" = "ID")
  )
```

### Round 2 Coding

Figure out what to check and export that file for the second coding check. 

```{r}
DF_Second <- DF %>% 
      filter(!is.na(round2_coder)) %>% 
      select(-c(TimeStamp, TimeStarted, DateStarted, OA,
                TimeEnded, DateEnded, Year, year_split, clickable_doi, 
                coder, Source.title, round2_coder)) %>% 
      group_by(ArticleID) %>% 
      mutate(coder_num = paste0("coder_", row_number())) %>% 
      ungroup() %>% 
      pivot_longer(cols = -c(ArticleID, coder_num, Coder)) %>% 
      pivot_wider(id_cols = c(ArticleID, name),
                  names_from = coder_num, 
                  values_from = c(value, Coder))
  
  # original code that excluded NA values and matches #
  # this excluded things I didn't mean to that #
  # were potentially not matches #
  # filter(!is.na(easy_screen)) %>% 
  # filter(easy_screen == F) %>% 
  # mutate(check = rep(c("EB", "KC", "IC", "CH"), length.out = nrow(.)))

export(DF_Second, "second_coder_check.csv", row.names = F)
#export(DF_Second, "analysis/second_coder_check.csv", row.names = F)

```

Import and examine the results from the second coding check. 

First, EMB noticed that she did not print out the article mismatches for review that had one NA value and one real value, which would generally be a mismatch. Given the group discussion described below and a few apparent miscodings, EMB recoded all the mismatches as described: (note that the original coding is avaliable in the excel document imported below second_coder_done.xlsx on a second sheet)

- The "unclear" category was added to indicate it was unclear if it was a mismatch because the person may have skipped answering these questions if they did not think the article was about language or did not have access. Therefore, all articles with one coder NA value and one coder real text was coded as Unclear.
- A not available and not applicable was coded as a match.
- A partial category was added for answers that overlapped but weren't exactly the same.

We also separately coded JIF because only a few members had access to the information in a specialized database. 

```{r}
DF_Second_import <- import("second_coder_done.xlsx")
#DF_Second_import <- import("analysis/second_coder_done.xlsx")


DF_Second_match <- DF %>% filter(!is.na(round2_coder)) %>% 
  select(-c(TimeStamp, TimeStarted, DateStarted, OA, 
            TimeEnded, DateEnded, Year, year_split, clickable_doi, 
            coder, Source.title, round2_coder)) %>% 
  group_by(ArticleID) %>% 
  mutate(coder_num = paste0("coder_", row_number())) %>% 
  ungroup() %>% 
  select(-Coder) %>% 
  pivot_longer(cols = -c(ArticleID, coder_num)) %>% 
  pivot_wider(id_cols = c(ArticleID, name), 
              names_from = coder_num, 
              values_from = value) %>% 
  mutate(easy_screen = coder_1 == coder_2) %>% 
  left_join((DF_Second_import %>% select(ArticleID, answer, name, corrected_answer)), 
            by = c("ArticleID" = "ArticleID", 
                   "name" = "name"))

# comparison table of screenings (easy is exact match)
table("easy" = DF_Second_match$easy_screen, 
      "coded" = DF_Second_match$answer, 
      useNA = "ifany")

# overall agreement
table(DF_Second_match$answer, useNA = "ifany")

# table of agreement before exclusion of first question mismatches
table(DF_Second_match$answer, 
      DF_Second_match$name,
      useNA = "ifany") / 120 * 100
```

Overall these results indicate a need to examine:

- Articles Issues (this was true before recoding)
- JIF was recoded (see below)

In a group discussion, we first discovered that the "mismatches" were often from one person indicating they did not have access to the article or disagreeing over if the article was about language. This first question would then lead to all other questions being in disagreement (and likely the unclear category mentioned above - therefore this was a problem in the `ArticleIssues` column). 

Since the goal was to reach 250 articles in each pre and post era, we excluded all articles that were a mismatch because of these two issues (did not have access, article about language). We then recalculated the agreement statistics for the double coded articles in which both articles were actually coded. 

```{r}
# print out articles that match 
agree_list <- DF_Second_match %>% 
  filter(answer == TRUE) %>% 
  filter(name == "ArticleIssues") %>% 
  pull(ArticleID)

length(agree_list)

# create a DF of just ones that agree past Article Issues
DF_Second_match_agree <- DF_Second_match %>% filter(ArticleID %in% agree_list)

# now examine for mismatches 
table(DF_Second_match_agree$answer, 
      DF_Second_match_agree$name,
      useNA = "ifany") / 98 * 100
```

After excluding articles that did not agree on the first item (and recoding above), we found that coders appeared to partially to completely agree at our threshold level. 

### Number of Articles

```{r}
# make DF that's not the second coding
# break in data here 2022-03-10 17:13:23
DF <- DF %>% filter(TimeStamp < as.POSIXct("2022-03-14"))

# did we reach our goal?
table(DF$ArticleIssues, DF$year_split, useNA = "ifany")

# table of double match
  #grab all articles that weren't double coded
  not_double <- DF %>% filter(!(ArticleID %in% DF_Second_match$ArticleID)) %>% pull(ArticleID)

DF_agree <- DF %>% filter(ArticleID %in% c(not_double, agree_list))
table(DF_agree$ArticleIssues, DF_agree$year_split, useNA = "ifany")
```

### Merge Partial/Unclear Answers

```{r}
# don't judge me on the loop ok 
DF_fix <- import("coder_abritration.xlsx") %>% 
#DF_fix <- import("analysis/coder_abritration.xlsx") %>% 
  filter(include == "included") %>% 
  filter(!is.na(corrected_answer))

for (i in 1:nrow(DF_fix)){
  DF_agree[
    DF_agree$ArticleID == DF_fix$ArticleID[i], # article match 
    DF_fix$name[i] # variable match
    ] <- DF_fix$corrected_answer[i]
}
```

```{r}
# rename DF to ensure match to rest of code
DF <- DF_agree
```

The following sections are in order of our preregistered plan: https://osf.io/j2q5p

## Article Characteristics

- Coder instructions: To identify journal impact factors use the Thomson Reuters Journal Citation Reports (https://jcr.clarivate.com/). For the question about the country, check the institutional affiliation of the corresponding author. If there are multiple corresponding authors, choose the first. If no corresponding author is identified, choose the first. If there are multiple affiliations for the selected author, choose the first. For the questions about study design, examine the title, abstract, and if necessary the methods section, to establish the study characteristics.

### Publication Information

- Publication year
  - Derived from Scopus meta-data
- Field
  - Derived from Scopus meta-data

```{r}
#DF$Year[DF$ArticleID == "795dfcd3"] <- 2008
table(DF$Year, useNA = "ifany")

DF$Source.title[DF$ArticleID == "9586644"] <- "Artificial Intelligence Review"
DF$Source.title[DF$ArticleID == "4.16E+06"] <- "Reading & Writing Quarterly"
DF$Source.title[DF$ArticleID == "9923056"] <- "Applied Linguistics"
DF$Source.title[DF$ArticleID == "5.84E+59"] <- "Language, Culture and Curriculum"
DF$Source.title[DF$ArticleID == "8.86E+11"] <- "International Journal of Lexicography"

table(DF$Source.title, useNA = "ifany")
```

### Language Investigated

- What language does the article investigate?
  - Free text response (multiple responses possible)
  - Additional instructions: "Multiple responses possible. If there are more than 5 languages refer to as  "cross linguistic". If in doubt, refer to as "unclear". If article makes claim about all languages, refer to as "universal"

```{r}
# lower case to normalize
DF$ArticleLanguage <- tolower(DF$ArticleLanguage)
# normalizing
DF$ArticleLanguage <- gsub("$mandarin^", "chinese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("bilingual english-mandarin", "english, chinese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('asl', 'american sign language', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('\\/', ',', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub(' and ', ',', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('cross linguistic', 'cross-linguistic', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("english as a second language", "english", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("esl", "english", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("l2 ", "", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("irish english|tyneside english", "english", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("standard greek", "greek", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("portugese", "portuguese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("chinese-cantonese", "chinese", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("nederlandse gebarentaal", "dutch sign language", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("shetland, scottish", "", DF$ArticleLanguage)
DF$ArticleLanguage <- gsub('"|old|\\(|\\)|subjects:|stimuli:|\\?|as a second language|shetland|middle|mandarin|european|cameroon|british|-putonghua|cypriot|fiji', '', DF$ArticleLanguage)
DF$ArticleLanguage <- gsub("multilingual context 10\\+ languages", "cross-linguistic", DF$ArticleLanguage)
DF$ArticleLanguage <- trimws(DF$ArticleLanguage)

langDF <- DF %>% 
  select(ArticleLanguage, year_split, ArticleID) %>% 
  separate(ArticleLanguage, sep = ",", into = c("A", "B", "C", "D"), 
           extra = "warn") %>% 
  pivot_longer(cols = c(A,B,C,D)) %>% 
  filter(!is.na(value)) %>% 
  select(year_split, value, ArticleID) %>% 
  rename(language = value) %>% 
  filter(language != "")

# these damned "spaces" what a dumb hack
langDF$language <- gsub("[^[:alnum:]]", "9", langDF$language)
langDF$language <- gsub("^9+(.+)", "\\1", langDF$language)
langDF$language <- gsub("(.+)9+$", "\\1", langDF$language)
langDF$language <- gsub("9", " ", langDF$language)

# final language table overall
table(langDF$language)

# final language table by split
table(langDF$language, langDF$year_split)

# average number of languages
count_lang <- langDF %>% 
  group_by(ArticleID) %>% 
  summarize(sample_size = n()) 

describe(count_lang$sample_size)

lang_summary <- langDF %>% 
  group_by(language, year_split) %>% summarise(frequency=n()) %>% 
  ungroup() %>% 
  arrange(desc(frequency)) %>%
  mutate(language=factor(tools::toTitleCase(language),levels = unique(tools::toTitleCase(language)),ordered = T)) %>% 
  filter(language %in% c("English", "Universal", "Spanish", "Chinese", "Cross Linguistic", "French", "German", "Polish")) %>% 
  mutate(year_split = factor(year_split, levels = c("Pre-OS", "After-OS")))


ggplot(lang_summary, aes(language, frequency,
                         color = year_split, fill = year_split)) + 
  geom_bar(stat = "identity", position = position_dodge()) + 
  theme_classic() + 
  ylab("Frequency") + 
  xlab("Language") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.4)) +
  scale_color_discrete(name = "Publication Year") + 
  scale_fill_discrete(name = "Publication Year")


# TR enters ;)

'%!in%' <- function(x,y)!('%in%'(x,y))

lang_summary_all <- langDF %>% 
  mutate(language_new = ifelse(language %!in% c("english", "universal", "spanish", "chinese", "cross linguistic", "german"),
                           "other", language)) %>% 
  group_by(language_new, year_split) %>% 
  summarise(frequency = n()) %>% 
  ungroup() %>% 
  mutate(language_new=factor(tools::toTitleCase(language_new),levels = unique(tools::toTitleCase(language_new)),ordered = T)) %>% 
  mutate(year_split = factor(year_split, levels = c("Pre-OS", "After-OS")))

# please someone make this in one pipeline
freq_split <- lang_summary_all %>% 
  group_by(year_split) %>% 
  summarise(frequency_split = sum(frequency)) %>% 
  ungroup() %>% 
  full_join(lang_summary_all) %>% 
  mutate(prop = round(frequency / frequency_split, 3) * 100) %>% 
  group_by(year_split) %>% 
  arrange(desc(prop)) %>%
  ungroup()


donut_languages <- ggplot(freq_split, aes(x = year_split, y = prop, fill = language_new)) +
  geom_col() +
  coord_polar("y") +
  labs(title = "A: Proportion of languages under investigation",
       subtitle = "inner ring = 2008/09; \nouter ring = 2018/19") + 
  scale_x_discrete(limits = c(" ", "Pre-OS","After-OS")) +
  guides(fill = guide_legend(title="Target Language(s)")) +
  theme_void() +
  scale_fill_viridis_d() +
  theme(
    legend.position = "left",
    plot.title = element_text(face = "bold",
                                       size = 14),
    plot.subtitle = element_text(size = 12),
    plot.title.position = "plot"
  )
 

```

### JIF 

- Journal impact factor at year of publication
  - What is the journal impact factor of the article at the time of publication?.
  - Free text response (numerical)
  - Additional instructions: "To identify journal impact factors use the Thomson Reuters Journal Citation Reports (https://jcr.clarivate.com/). If you have no access to the website, code as "NO ACCESS", if no JIF is available for year of publication, take first available JIF after year of publication and note the year of JIF in 2.2b below. If no JIF is available at all, code as NA."
- Year of journal impact factor (if not = year of publication)
  - What is the year of journal impact factor (if not = year of publication)
  - Free text response (numerical)
  
**Note**: We had a separate group code JIF, as only a few had access to the database with these values. 

```{r}
JIF <- import("JIF_update.xlsx")
#JIF <- import("analysis/JIF_update.xlsx")
# describe jif
describeBy(as.numeric(JIF$JIF), group = JIF$Year)

# enter TR
JIF_new <- JIF %>%  
  filter(JIFYear != "NA") %>% 
  mutate(JIF = as.numeric(JIF),
         JIFYear = as.numeric(JIFYear),
    year_split = ifelse(JIFYear > 2016, "After-OS", "Pre-OS"))

JIF_plot <- 
ggplot(JIF_new,
       aes(x = JIF, fill = year_split)) + 
  geom_density(alpha = 0.5,
               color = "white") +
  geom_point(y = 0, 
             pch = 21,
             color = "white",
             alpha = 0.5,
             show.legend = F) +
  labs(title = "B: Distribution of JIF across sample",
       subtitle = "displaying an slight upward trend of journals in later years") + 
  guides(fill = guide_legend(title = "Time Frame")) +
  scale_fill_viridis_d() +
  theme_minimal() + 
  theme(legend.position = c(0.9,0.8),
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
         plot.title = element_text(face = "bold",
                                       size = 14),
        plot.subtitle = element_text(size = 12))


# DF %>% select(JIF, JIFYear, ArticleID, Source.title, Year) %>% 
#   export(x = ., file = "jif_update.csv", row.names = F)
```

### Country

- Which country is the corresponding author based in according to their affiliation?
  - USA / China / UK / Germany / Japan / France / Canada / Italy / India / Spain /  /Unclear /Other *
  - Additional instructions: "For the question about the country, check the institutional affiliation of the corresponding author. If there are multiple corresponding authors, choose the first. If no corresponding author is identified, choose the first. If there are multiple affiliations for the selected author, choose the first."

```{r}
# fix up typos
DF$CountryAuthor <- gsub("The Netherands", "The Netherlands", DF$CountryAuthor)
DF$CountryAuthor <- gsub("The Netherlands", "Netherlands", DF$CountryAuthor)
DF$CountryAuthor <- gsub("Hongkong", "Hong Kong", DF$CountryAuthor)

DF$CountryAuthor <- gsub("Finnland", "Finland", DF$CountryAuthor)
DF$CountryAuthor <- gsub("Republic of Ireland", "Ireland", DF$CountryAuthor)
DF$CountryAuthor <- gsub("Republic of South Africa", "South Africa", DF$CountryAuthor)
DF$CountryAuthor <- gsub(", Germany", "", DF$CountryAuthor)
DF$CountryAuthor <- gsub(", Poland", "", DF$CountryAuthor)
DF$CountryAuthor <- gsub("Brasil", "Brazil", DF$CountryAuthor)

table(DF$CountryAuthor)

DF$CountryCode <- countrycode(sourcevar = DF$CountryAuthor,
                              origin = 'country.name', 
                              destination = 'iso2c')

world_map <- map_data(map = "world")
world_map$region <- iso.alpha(world_map$region)

country_summary <- DF %>% 
      group_by(CountryCode) %>% 
      summarize(n = n())

ggplot(country_summary) +
  geom_map(aes(map_id = CountryCode, fill = n), map = world_map) +
  geom_polygon(data = world_map, aes(x = long, y = lat, group = group), colour = 'black', fill = NA) + 
  theme_void() + 
  scale_fill_continuous(name = "Sample Size")


# TR enters ;) UK, USA, Australia, Germany, China, Netherlands, Spain

country_summary_new <- DF %>% 
   mutate(CountryAuthor_new = ifelse(CountryAuthor %!in% c("UK", "USA", "Australia", "Germany", "China", "Netherlands", "Spain"), "Other", CountryAuthor)) %>% 
      group_by(CountryAuthor_new, year_split) %>% 
      summarize(frequency = n()) %>% 
      ungroup()
  
country_split <- country_summary_new %>% 
  group_by(year_split) %>% 
  summarise(frequency_split = sum(frequency)) %>% 
  full_join(country_summary_new) %>% 
  mutate(prop = round(frequency / frequency_split, 3) * 100)



donut_countries <- ggplot(country_split, aes(x = year_split, y = prop, fill = CountryAuthor_new)) +
  geom_col() +
  coord_polar("y") +
  labs(title = "B: Proportion of author's host country",
       subtitle = "inner ring = 2008/09; \nouter ring = 2018/19") + 
  scale_x_discrete(limits = c(" ", "Pre-OS","After-OS")) +
  guides(fill = guide_legend(title="Host Country(s)")) +
  theme_void() +
  scale_fill_viridis_d() +
  theme(
    plot.title = element_text(face = "bold",
                                       size = 14),
    plot.subtitle = element_text(size = 12),
    plot.title.position = "plot"
  )

sample_characteristics <- donut_languages + donut_countries 

ggsave(filename = "plots/sample_characteristics.png",
       plot = sample_characteristics,
       device = "png",
       width = 360, 
       height = 150,
       units = "mm", 
       dpi = 500)

```

### Study type/design

- What type of study is being reported?
  - Multiple choice (see Table 2 for response options).
  - Additional instructions: "Mark only one oval. Examine the title, abstract, and if necessary the methods section, to establish the study characteristics."

```{r}
DF$StudyType[grepl("^No empirical data", DF$StudyType)] <- "No empirical data"
table(DF$StudyType)
```

### Type of empirical study

- If the article reports empirical data, what type of empirical data study is being reported?
  - Experimental study / 
  - Corpus study / 
  - Field study or language description / 
  - Survey or interview / 
  - Typological study /   
  - Multiple study type reported / 
  - Other
  
```{r}
DF$EmpiricalStudyData <- sub(" with no systematically sampled material, just selected examples ", "", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- sub(", Not language per se but report about reading experiences was analysed qualitatively", "", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- sub("(only 6 patients, all tested on battery of tasks)", "", DF$EmpiricalStudyData)
DF$EmpiricalStudyData <- trimws(tolower(DF$EmpiricalStudyData))

studyDF <- DF %>% 
  select(EmpiricalStudyData, year_split, ArticleID) %>% 
  separate(EmpiricalStudyData, sep = ",", into = c("A", "B", "C"), 
           extra = "warn") %>% 
  pivot_longer(cols = c(A,B,C)) %>% 
  filter(!is.na(value)) %>% 
  select(year_split, value, ArticleID) %>% 
  rename(study = value) %>% 
  filter(study != "")

# these damned "spaces" what a dumb hack
studyDF$study <- sub("case studies", "case study", studyDF$study)
studyDF$study <- sub("could be also considered collection of case study.*", "case study", studyDF$study)
studyDF$study <- sub(" with no systematically sampled material", "", studyDF$study)
studyDF$study <- sub("partly also ", "", studyDF$study)
studyDF$study <- gsub("observation.*", "observation", studyDF$study)
studyDF$study <- gsub("intervention.*", "observation", studyDF$study)
studyDF$study <- gsub(".*modelling.*", "modelling", studyDF$study)
studyDF$study <- sub("interviews", "survey or interview", studyDF$study)
studyDF$study <- gsub("[^[:alnum:]]", "9", studyDF$study)
studyDF$study <- gsub("^9+(.+)", "\\1", studyDF$study)
studyDF$study <- gsub("(.+)9+$", "\\1", studyDF$study)
studyDF$study <- gsub("9", " ", studyDF$study)

table(studyDF$study)

study_summary <- studyDF %>% 
  group_by(study, year_split) %>% summarise(frequency=n()) %>% 
  ungroup() %>% 
  arrange(desc(frequency)) %>%
  mutate(study=factor(tools::toTitleCase(study),levels = unique(tools::toTitleCase(study)),ordered = T)) %>% 
  filter(frequency >= 8) %>% 
  mutate(year_split = factor(year_split, levels = c("Pre-OS", "After-OS")))

ggplot(study_summary, aes(study, frequency,
                         color = year_split, fill = year_split)) + 
  geom_bar(stat = "identity", position = position_dodge()) + 
  theme_classic() + 
  ylab("Frequency") + 
  xlab("Study Type") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.4)) +
  scale_color_discrete(name = "Publication Year") + 
  scale_fill_discrete(name = "Publication Year")
```

## Preregistration

- Definitions: "Preregistration" refers to the timestamped registration of important aspects of the study (typically hypotheses, methods, and/or analysis plan) prior to commencement of the study.
- Coder instructions: Check specific sections where these files might be located e.g., supplementary materials, appendices, author notes, methods, and results sections. Search for "*registration" or "*registered".

### Preregistration

- Does the article state whether or not the study (or some aspect of the study) was preregistered?
  - Yes – there is a preregistration/
  - No – there is no preregistration/ 
  - Other*

```{r}
table(DF$PreReg)
```

### Preregistration method

- Where does the article indicate the preregistration is located?
  - Open Science Framework (osf.io) /
  - AsPredicted (aspredicted.org) /
  - Registered Report /
  - Other*
  
```{r}
table(DF$PreRegWhere)
```

### Preregistration accessible

- Can you access and open the preregistration?
  - Yes / No / Other*
  
```{r}
table(DF$PreRegAccess)
```

### Preregistration content

- What aspects of the study appear to be preregistered? (select all that apply)
  - Hypotheses /
  - Data collection /
  - Analysis /
  - Other*
  
```{r}
table(DF$PreRegAspects)
```

## Data sharing

- Definitions: "data" refers to recorded information that supports the analyses reported in the article. For our purposes, we differentiate between different types of data. "Raw data" refers to the recorded information in its rawest, digital form, at the level of sampling units (e.g., participants, words, utterances, trials, etc). "Processed data" refers to a derived form of the data that has undergone changes from its raw state (e.g., extraction of acoustic parameters via Praat, aggregates of responses, etc.).
- A "data availability statement" can be as simple as a url link to a data file, or as complex as a written explanation as to why data cannot be shared. 
- Coder instructions: Check the article for a data availability statement/link. They are often located in the "supplementary material", "acknowledgements", "author notes", "methods", or "results" sections. Search the article for the text "data availab*" (to cover "data availability" and "data available"). Search for links using "www" or "http". 

### Raw data type

- What is the nature of the raw data files?
  - Not applicable /
  - Text file /
  - Audio /
  - Video / 
  - Images /
  - Other

```{r}
DF$RawData <- sub("Individual examples of linguistic phenomenon >> text files\\?", "Text file", DF$RawData)
DF$RawData <- sub("Not applicable, Examples of analyzed sentences provided in article text", "Not applicable", DF$RawData)
DF$RawData <- sub("Not applicable, Examples of sentences in text \\(syntactic analysis\\)", "Not applicable", DF$RawData)
DF$RawData <- sub('survey results: choices of single vowels >> counts as "text"\\?', "Text file", DF$RawData)
DF$RawData <- sub("single examples", "Text file", DF$RawData)
DF$RawData <- sub(", Answers obtained from stimuli items", "", DF$RawData)
DF$RawData <- sub(", Survey responses", "", DF$RawData)
DF$RawData <- sub(", individual examples in article >> text files\\?", "", DF$RawData)
DF$RawData <- sub(', results of experiment with reaction times >> counts as "text"\\?', "", DF$RawData)
DF$RawData <- sub(", online corpus", "", DF$RawData)

table(DF$RawData)

dataDF <- DF %>% 
  select(RawData, year_split, ArticleID) %>% 
  separate(RawData, sep = ",", into = c("A", "B", "C"), 
           extra = "warn") %>% 
  pivot_longer(cols = c(A,B, C)) %>% 
  filter(!is.na(value)) %>% 
  select(year_split, value, ArticleID) %>% 
  rename(data = value) %>% 
  filter(data != "")

dataDF$data <- gsub("[^[:alnum:]]", "9", dataDF$data)
dataDF$data <- gsub("^9+(.+)", "\\1", dataDF$data)
dataDF$data <- gsub("(.+)9+$", "\\1", dataDF$data)
dataDF$data <- gsub("9", " ", dataDF$data)

data_summary <- dataDF %>% 
  group_by(data, year_split) %>% summarise(frequency=n()) %>% 
  ungroup() %>% 
  arrange(desc(frequency)) %>%
  mutate(data=factor(tools::toTitleCase(data),levels = unique(tools::toTitleCase(data)),ordered = T)) %>% 
  filter(frequency >= 8) %>% 
  mutate(year_split = factor(year_split, levels = c("Pre-OS", "After-OS")))

ggplot(data_summary, aes(data, frequency,
                         color = year_split, fill = year_split)) + 
  geom_bar(stat = "identity", position = position_dodge()) + 
  theme_classic() + 
  ylab("Frequency") + 
  xlab("Data Type") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.5, hjust=0.4)) +
  scale_color_discrete(name = "Publication Year") + 
  scale_fill_discrete(name = "Publication Year")
```

### Raw data statement

- Does the article state whether or not raw data are available?
  - Yes, the statement says that the raw data are available /
  - No - raw data are not available.(GO TO SECTION 4.6) / 
  - Other*
  
```{r}
DF$RawDataAvl <- sub(".*corp.*", "Yes - Corpus", DF$RawDataAvl)
DF$RawDataAvl <- sub("No statement but links to data sources|Raw data \\(examples\\) are provided within the publication", "Yes, the statement says that the raw data are available.", DF$RawDataAvl)
DF$RawDataAvl <- sub(".*third.*", "Yes - Third Party", DF$RawDataAvl)
DF$RawDataAvl <- sub("State that the data is no longer available", "No, raw data are not available.  (GO TO SECTION 4.6)", DF$RawDataAvl)
DF$RawDataAvl <- sub("Some raw data available", "Yes, the statement says that the raw data are available.", DF$RawDataAvl)

table(DF$RawDataAvl)
```

### Raw data sharing method

- How does the statement indicate that the raw data are available?
  - Upon request from the authors / 
  - Personal or institution website / 
  - An online, third-party repository (e.g., OSF, GitHub, FigShare etc.) / 
  - Supplementary materials hosted by the journal /
  - Available from a third party /
  - Unclear /
  - Other*

```{r}
DF$RawDataWhere <- sub("as part of the article \\(individual examples\\)|raw data are available as individual examples in the article", "In Article", DF$RawDataWhere)
DF$RawDataWhere <- sub("Blog", "Personal or institutional website", DF$RawDataWhere)
DF$RawDataWhere <- sub(".*corpus.*", "Available from a third party", DF$RawDataWhere)
DF$RawDataWhere <- sub("Links to online sources, one does not work", "Available from a third party", DF$RawDataWhere)
table(DF$RawDataWhere)
```

### Raw data accessibility

- Can you access, download, and open the raw data files without an additional step such as a sign-up or a login?
  - Yes / No / Other*
  
```{r}
table(DF$RawDataAccess)
```
  
### Raw data documentation

- Are the raw data files documented, i.e., are there meta-data that state the nature and content of individual files? For text files, is there a data dictionary / "code book" that describes the nature of individual variables?
  - Yes / No / Unclear / Other*
  
```{r}
table(DF$RawDataDocument)
```

### Processed data statement

- Does the article state whether or not processed data are available?
  - Yes, the statement says that the processed data are available /
  - No, processed data are not available. / 
  - Other*

```{r}
DF$ProcessData <- sub(" \\(GO TO SECTION 5\\)", "", DF$ProcessData)
table(DF$ProcessData)
```

### Processed data sharing method

- How does the statement indicate that the processed data are available?
  - Upon request from the authors / 
  - Personal or institution website / 
  - An online, third-party repository (e.g., OSF, GitHub, FigShare etc.) / 
  - Supplementary materials hosted by the journal /
  - Available from a third party /
  - Unclear /
  - Other*

```{r}
table(DF$ProcessDataWhere)
```

### Processed data accessibility

- Can you access, download, and open the processed data files without an additional step such as a sign-up or a login?
  - Yes / No / Other*
  
```{r}
table(DF$ProcessDataAccess)
```

### Processed data documentation

- Are the processed data files documented, i.e., are there meta-data that state the nature and content of individual files? Is there a data dictionary / "code book" that describes the nature of individual variables?
  - Yes / No / Unclear / Other*
  
```{r}
table(DF$ProcessDataDocument)
```

## Analysis script sharing

Definition: "Analysis scripts" refers to specification of data preparation and analysis steps in the form of highly detailed step-by-step instructions for using point-and-click software (e.g., SPSS), analysis code (e.g., R), or syntax (e.g., from SPSS). 
- Coder instructions: Check the article for an analysis script availability statement/link. They are often located in the "supplementary material", "acknowledgements",  "author notes", "methods", or "results" sections. Search for the text "analysis script" and "analysis code". Search for links using "www" or "http". 

### Analysis script availability 

- Are analysis scripts available?
  - Yes, analysis scripts are freely available / 
  - Authors point to a third party /
  - No, analysis scripts are not available /
  - Other*

```{r}
DF$AnalysisScript <- sub(" \\(GO TO SECTION 6\\)", "", DF$AnalysisScript)
DF$AnalysisScript <- sub(".*Not applicable.*|The study did not necessitate an analysis script", "Not Applicable", DF$AnalysisScript)
table(DF$AnalysisScript)
```

### Analysis script sharing method

- How are the analysis scripts accessible?
  - Upon request from the authors / 
  - Personal or institution website / 
  - An online, third-party repository (e.g., OSF, GitHub, FigShare etc.) / 
  - Supplementary materials hosted by the journal /
  - Available from a third party /
  - Unclear /
  - Other*
  
```{r}
table(DF$AnalysisScriptWhere)
```  

### Analysis script accessibility

- Can you access, download, and open the analysis scripts without an additional step such as a sign-up or a login?
  - Yes / No / Other*

```{r}
table(DF$AnalysisScriptAccess)
```

## Materials / Methods sharing

- Definitions: "materials / methods" refers to any study items that would be needed to repeat the study, such as stimuli, survey instruments, and computer code/software used for data collection, presentation stimuli or running experiments (not including analysis scripts, see next section), study protocols, etc. For present purposes we do not consider supplementary data/findings (e.g., additional figures or tables) to be ‘materials’.
- Coder instructions: Check the article for a materials / methods availability statement/link. They are often located in the "supplementary material", "acknowledgements",  "author notes", "methods", or "results" sections. Search for links using "www" or "http".

### Materials availability 

- Are materials or additional information about the method available?
  - Yes, materials or additional information about the method are freely available / 
  - Materials or additional information available through a third party /
  - No, materials or additional information about the method are not available /
  - Other*
  
```{r}
DF$Materials <- sub(".*dead.*", "Dead Links", DF$Materials)
DF$Materials <- sub(" \\(GO TO SECTION 7\\)", "", DF$Materials)
DF$Materials <- sub(".*Not applicable.*", "Not Applicable", DF$Materials)
DF$Materials <- sub(".*Supplementary.*|.*Append.*|.*append.*", "Appendix", DF$Materials)
DF$Materials <- sub(".*third.*|Links to online corpora provided", "Third Party", DF$Materials)

table(DF$Materials)
```
  
### Materials sharing method

- How are the materials or additional information about the method accessible?
  - Upon request from the authors / 
  - Personal or institution website / 
  - An online, third-party repository (e.g., OSF, GitHub, FigShare etc.) / 
  - Supplementary materials hosted by the journal /
  - Available from a third party /
  - Unclear /
  - Other*

- Additional instructions: "If authors point to a third party via a reference only, mark "Available from a third party"."

```{r}
DF$MaterialsWhere <- sub(".*append.*|.*Suppl.*|.*Append.*|In the actual article", "Appendix", DF$MaterialsWhere)
DF$MaterialsWhere <- sub(".*brok.*|.*dead.*", "Dead Links", DF$MaterialsWhere)
DF$MaterialsWhere <- sub(".*some materials.*", "Some materials shared", DF$MaterialsWhere)
DF$MaterialsWhere <- sub(".*Some materials.*|.*Some avail.*", "Some materials shared", DF$MaterialsWhere)

table(DF$MaterialsWhere)
```

### Materials accessibility

- Can you access, download, and open the materials or additional information about the method without an additional step such as a sign-up or a login?
  - Yes / No / Other*
  
```{r}
table(DF$MaterialsAccess)
```

## Replication

- Definition: "replication" refers to repetition of a previous study’s methods in order to ascertain whether similar findings can be obtained with a new sample. 
Coder instructions: Search the title and abstract for the phrase "replicat*" (to cover ‘replication’, ‘replicates’, etc). Confirm the authors are using the phrase with the definition provided above.

### Replication statement

- Does the article claim to report a replication study in abstract or title?
  - The article claims to report a replication study (or studies) / 
  - There is no clear statement that the article reports a replication study (or studies) / 
  - Other*
  
```{r}
table(DF$Replication)
```


## Conflict of interest

- Coder instructions: Conflicts of interest are usually reported in a specific section e.g., "Author information", "Conflict of interest statement", or "Acknowledgments". Search the article for the phrases "conflict of interest" and/or "competing interest".

### Conflict of Interest statement

- Does the article include a statement indicating whether there were any conflicts of interest?
  - Yes, the statement says that there are one or more conflicts of interest /
  - Yes, the statement says that there is no conflict of interest / 
  - No, there is no conflict of interest statement / 
  - Other*
  
```{r}
table(DF$COI)
```

## Open access

- Coder instructions: To establish the open access status of the article: Ensure you are not connected to a network that grants paid access to journals (e.g., a university network) or logged into a remote access system such as Shibboleth or OpenAthens. Go to https://unpaywall.org/ and add the browser extension to your browser. Restart your browser. Enter the article’s DOI URL, this should lead you to the publisher’s website. Click on the unpaywall button to the right of the screen to access an open access version of the article (if the button is green, there is an OA version, if the button is grey, there is no OA version). If the article is accessible, answer "Yes". If the article is not accessible via the add-on, answer "No".

### Open access status

- Is the article open access?
  - Yes, is open access on the publisher's website via gold OA /
  - Yes, is open access via unpaywall (somewhere else) /
  - No, can only be accessed via subscription l/ 
  - Other*

```{r}
table(openaccessDF$open_access)
```

### ideas

- show with everything to show small categories
- zoom in on those that did one to look at those proportions 
- river plot - conditional probabilities if i do one practice what other ones do I tend to do
- be sure to consider scaling issue 

